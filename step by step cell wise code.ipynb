{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qy3EKWoKfXzt"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets xgboost scikit-learn tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.utils import class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Conv1D, GlobalMaxPooling1D, LSTM, Bidirectional, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n"
      ],
      "metadata": {
        "id": "hjZRiQftlFlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "UPxCJKpnl6X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "file_path = '/content/drive/My Drive/thesis/thesis 2.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "df = df[['Text', 'Label']]\n",
        "df.dropna(inplace=True)\n",
        "print(\"Dataset shape:\", df.shape)"
      ],
      "metadata": {
        "id": "EIiVllzjl6Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def encode_texts(texts, max_len=128):\n",
        "    return tokenizer(\n",
        "        list(texts),\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_len,\n",
        "        return_tensors=\"tf\"\n",
        "    )"
      ],
      "metadata": {
        "id": "8woykE8PmnmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bert_embeddings(model, texts, batch_size=32, max_len=128):\n",
        "    embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        encoded = encode_texts(batch_texts, max_len)\n",
        "        batch_output = model(encoded['input_ids'], attention_mask=encoded['attention_mask'])\n",
        "        batch_embeddings = batch_output.last_hidden_state[:, 0, :].numpy()  # CLS token\n",
        "        embeddings.append(batch_embeddings)\n",
        "        del encoded, batch_output\n",
        "        gc.collect()\n",
        "    return np.vstack(embeddings)\n"
      ],
      "metadata": {
        "id": "6qYRJntgoH3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "X = get_bert_embeddings(bert_model, df['Text'].values, batch_size=32)\n",
        "y = df['Label'].values"
      ],
      "metadata": {
        "id": "H4M_FJLyGR6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del bert_model\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "gLmTx-M3GyZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "fm8CTC0SouQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n"
      ],
      "metadata": {
        "id": "4KnHXdLYEM2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1: CNN + BERT + XGBoost\n",
        "input_layer = Input(shape=(X_train.shape[1], 1))\n",
        "x = Conv1D(128, kernel_size=3, activation='relu')(input_layer)\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "cnn_model = Model(inputs=input_layer, outputs=x)"
      ],
      "metadata": {
        "id": "4ylBkQgUovgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare CNN input\n",
        "X_train_cnn = np.expand_dims(X_train, axis=2)\n",
        "X_test_cnn = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "cnn_features_train = cnn_model.predict(X_train_cnn, batch_size=32)\n",
        "cnn_features_test = cnn_model.predict(X_test_cnn, batch_size=32)"
      ],
      "metadata": {
        "id": "17efysNwG_j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning for XGBoost\n",
        "xgb_params = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'n_estimators': [100, 200]\n",
        "}\n",
        "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "grid_search = GridSearchCV(xgb_model, xgb_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(cnn_features_train, y_train, sample_weight=[class_weight_dict[label] for label in y_train])"
      ],
      "metadata": {
        "id": "YAD9ZTzpHHx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best XGBoost model\n",
        "xgb_model_cnn = grid_search.best_estimator_\n",
        "print(\"Best CNN + XGBoost Params:\", grid_search.best_params_)\n",
        "y_pred_cnn = xgb_model_cnn.predict(cnn_features_test)"
      ],
      "metadata": {
        "id": "hyTns2tsHKkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save CNN models\n",
        "xgb_model_cnn.save_model('/content/drive/My Drive/thesis/cnn_xgboost_model.json')\n",
        "cnn_model.save('/content/drive/My Drive/thesis/cnn_model.h5')"
      ],
      "metadata": {
        "id": "6faNuFXpHKsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2: BiLSTM + BERT + XGBoost\n",
        "input_layer = Input(shape=(X_train.shape[1], 1))\n",
        "x = Bidirectional(LSTM(128, return_sequences=False))(input_layer)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "lstm_model = Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "lstm_features_train = lstm_model.predict(X_train_cnn, batch_size=32)\n",
        "lstm_features_test = lstm_model.predict(X_test_cnn, batch_size=32)\n"
      ],
      "metadata": {
        "id": "yD3_VN59HKvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning for XGBoost\n",
        "xgb_model_lstm = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "grid_search_lstm = GridSearchCV(xgb_model_lstm, xgb_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_search_lstm.fit(lstm_features_train, y_train, sample_weight=[class_weight_dict[label] for label in y_train])"
      ],
      "metadata": {
        "id": "7_1eqyHlHKxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best XGBoost model\n",
        "xgb_model_lstm = grid_search_lstm.best_estimator_\n",
        "print(\"Best BiLSTM + XGBoost Params:\", grid_search_lstm.best_params_)\n",
        "y_pred_lstm = xgb_model_lstm.predict(lstm_features_test)"
      ],
      "metadata": {
        "id": "jWUBF2opHUwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save BiLSTM models\n",
        "xgb_model_lstm.save_model('/content/drive/My Drive/thesis/lstm_xgboost_model.json')\n",
        "lstm_model.save('/content/drive/My Drive/thesis/lstm_model.h5')"
      ],
      "metadata": {
        "id": "k1NyQK9HHUy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation and visualization function\n",
        "def evaluate_and_plot(y_true, y_pred, model_name, classes):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\nðŸ“Š Evaluation for {model_name}:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "    return accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "XfQYmPlfHU2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate both models\n",
        "classes = np.unique(y)\n",
        "cnn_metrics = evaluate_and_plot(y_test, y_pred_cnn, \"CNN + BERT + XGBoost\", classes)\n",
        "lstm_metrics = evaluate_and_plot(y_test, y_pred_lstm, \"BiLSTM + BERT + XGBoost\", classes)"
      ],
      "metadata": {
        "id": "DNbntmkTHctI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot metric comparison\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "plt.figure(figsize=(10, 6))\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "plt.bar(x - width/2, cnn_metrics, width, label='CNN + BERT + XGBoost', color='#1f77b4')\n",
        "plt.bar(x + width/2, lstm_metrics, width, label='BiLSTM + BERT + XGBoost', color='#ff7f0e')\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Scores')\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.xticks(x, metrics)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VqcxOYPYHc3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results to CSV\n",
        "results = pd.DataFrame({\n",
        "    'Metric': metrics,\n",
        "    'CNN + BERT + XGBoost': cnn_metrics,\n",
        "    'BiLSTM + BERT + XGBoost': lstm_metrics\n",
        "})\n",
        "results.to_csv('/content/drive/My Drive/thesis/model_results.csv', index=False)\n",
        "print(\"Results saved to /content/drive/My Drive/thesis/model_results.csv\")"
      ],
      "metadata": {
        "id": "n7MKszIiHK0s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}